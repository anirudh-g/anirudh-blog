{
  
    
        "post0": {
            "title": "Thoughts on fastbook",
            "content": "If you can‚Äôt explain it in simple terms, then you don‚Äôt understand it . This quote is something that we might have come across a lot of times. But how many of us have taken it seriously? . Well, the team at fastai has taken it seriously. They have created a deep learning course &amp; an accompanying book that uses simple terms to demistify some of the most complex topics in the field. I read the book version, which is called ‚ÄúDeep learning for Coders‚Äù a.k.a the fastbook. . I was pleasantly surprised by the book as it not only teaches the concepts in deep learning but also gives ideas, perspectives and a little nudge to even contribute back to the community. The best part is that all this is coming from an expert team at fastai led by the highly respected Dr.Jeremy Howard. . The book itself is broadly divided into 4 parts: . Practical deep learning | Deep learning applications | Foundations of deep learning | Deep learning from scratch | If you closely look at the flow of the structure above, it directly goes into practical and application based deep learning. Only then the foundations are taught. Why is it? Well, it is called the top-down learning approach. I found it to be refreshing as most my education was built on a bottom-up approach where I first learned the theory &amp; math behind the models and then moved to build the ML model. Here by allowing us to start from an application oriented persepctive, we can peel the layers of the framework by going deeper and deeper where we learn the nuts &amp; bolts of how things work from scratch. . All of this is made even better by the fantastic community built around the fastai framework and the book. To give a peek of the powerful community, I am mentioning (in no particular order) some fastai community leaders and their contribution to enhancing the learning experience: . Aman Arora and W&amp;B team - The fastbook reading group A playlist that gives walk-through of the key chapters in the book in a lecture-like format | Zachary Mueller - A Walk with FastAI A series of lecturers &amp; notebooks which explores the fastai framework beyond the book by acting as a recipe book on steroids | Radek Osmulski - AI Quiz A website of quiz materials that cover the end-of-chapter questions in the fastbook by using a spaced repetition approach | . These are just the ones that I have come across while reading the book. There are numerous community members who have contributed their time and effort to make the fastbook more valauable and arguably the best book on deep learning. . To summarise everything in a couple of sentences - If I had to learn deep learning again, then the fastbook is the only material that I would learn it from. In fact going forward I have a few deep learning courses and books in my bucket list for 2022, but I have a strong feeling that none of them will come close to the value offered by the fastbook. . Some of my kaggle notebooks that I produced while reading the fastbook includes: . Blood Cell Classification | Casava Classification | Pet Popularity Prediction | Also, did I mention that the entire book is freely available as executable jupyter notebooks here. It cannot get better than this! . Thanks for reading the post. I hope it was of some help to you. If you liked the work, kindly consider sharing the article. Cheers, stay safe and enjoy a happy 2022! .",
            "url": "https://anirudh-g.github.io/anirudh-blog/books/2021/12/27/fastbookreview.html",
            "relUrl": "/books/2021/12/27/fastbookreview.html",
            "date": " ‚Ä¢ Dec 27, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "My learning paradigm",
            "content": "Long term consistency trumps short term intensity - Bruce Lee . This quote has formed the basis of my learning ever since my undergraduate days. However, it does not convey the full story here. Its because keeping up the motivation to learn in the long-term can be tough. Also, what is even more difficult is to remember a concept or a technique that you learnt 6-months ago. . Why am I saying all this? . Good question! I am here to share my learning paradigm that helps me keep motivation and memory in order to achieve long-term consistency in learning. There a few things which I follow : . The Solution approach** . | Spaced Repetition** . | The Solution approach . It is easy to loose motivation when you don‚Äôt work towards a target. For me, a target is a solution that can help solve an issue or make life easy for anyone who is using it. . Therefore, I follow these 2 steps: . Define the final solution that I want to create | Work backwards to figure out the steps that can enable me to build the best possible solution, given the resources | With this solution-based approach, I now have a target to work towards. In that process, I tend go out of my way to learn new tools and techniques to make my solution possible. . This appraoch helps keep up my motivation while also allowing me to get more learning out of the project than I originally intended to. . Spaced Repetition . It is human nature to forget things that we don‚Äôt use in our day-to-day life. Do I still remember my 12th grade physics concepts? Ofcourse not. Its because physics is not my area of study and as a result I never had the chance to use the learnings in my day-to-day work. . So getting a certificate on something but not using the learnings from it for a long-time means you forget all the knowledge you gained. Also in the that time, there can be updates or even groundup overhaul which makes your re-learning that much more difficult. . Therefore, I follow spaced repetition. That is: . I learn a concept by taking extensive notes about it | Then after a few months, I either re-read those notes or parts of the original material | With this spaced repetition, after a few iterations, the learning gets drilled into my brain that I almost always have everything at the top of my head. This makes the subsequent work and building on my existing knowledge as easy as riding a bike. . By using these 2 paradigms, I keep the long-term consistency in my learning journey. . Thanks for reading the post. I hope it was of some help to you. If you liked the work, kindly consider sharing the article. Cheers and stay safe! . Footnote - I am currently reading the book ‚ÄúDeep learning for Coders by Dr.Jeremy Howard‚Äù. So, do check back the website in a few weeks for a concise review of the same. .",
            "url": "https://anirudh-g.github.io/anirudh-blog/general/2021/11/08/mylearningparadigm.html",
            "relUrl": "/general/2021/11/08/mylearningparadigm.html",
            "date": " ‚Ä¢ Nov 8, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Work Experience . Data Scientist at Cognizant-Scorg üáÆüá≥ Sep 2021 - Present | Data Analyst Trainee at Prodian Infotech üáÆüá≥ Dec 2020 - Aug 2021 | . Academic Background . MS Data Science, University of Glasgow üá¨üáß Class of 2020 | B.Tech CSE, SRM University üáÆüá≥ Class of 2019 | Global Academic Internship Program on Data Science, National University of Singapore üá∏üá¨ Dec 2017 | . Skill Set . Programming Languages - Python &amp; SQL | APIs/Framworks - Scikit-learn, XGBoost, LightGBM, CatBoost, Tensorflow-Keras, Fast.ai, Nvidia Rapids (cuDF &amp; cuML), Optuna, Git, DVC, Streamlit and Docker | Viz Tools - Excel, Tableau, PowerBI | ML Platforms - DataRobot &amp; Azure ML Studio | . Open-source competitions . 2022 . (Kaggle) Image based Pet Popularly prediction : [Top 23%] - Rank 826 (of 3537 teams) | . 2021 . (MachineHack) Music genre prediction : [Top 13%] - Rank 49 (of 360) | (MachineHack) TheMathCompany hackathon : [Top 5%] - Rank 137 (of 2413) | . My goal is to conceptualise, design &amp; drive end-to-end machine learning products/solutions at scale and help make data-driven decisions using my expertise as Data Scientist . You can find me at LinkedIn, Twitter and Kaggle .",
          "url": "https://anirudh-g.github.io/anirudh-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "",
          "content": "Hello and welcome to my portfolio site and blog. . I am Anirudh Gokulaprasad, a Data Scientist with 1+ years of industry experience in building Data, Analytics &amp; Machine learning solutions in BFSI and Life Science domains. . My area of interest broadly includes Computer Vision, NLP &amp; Audio based AI applications. I am intrigued by the use of Explainable AI and its impact in business-critical and life-critical scenarios. I advocate for simplistic, readable &amp; highly maintainable code. . My long-term vision is to develop my skills in order to conceptualise, architect and drive end-to-end AI products and solutions at scale. . Check out the about section to know more about me. . Find my recent blog posts below. . Posts .",
          "url": "https://anirudh-g.github.io/anirudh-blog/",
          "relUrl": "/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://anirudh-g.github.io/anirudh-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}